{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from data import (\n",
    "    download_data_files,\n",
    "    validate_and_save_data,\n",
    "    transform_data,\n",
    "    add_missing_times,\n",
    "    transform_save_data_into_ts_data,\n",
    "    generate_training_set,\n",
    "    join_parquet_files\n",
    ")\n",
    "import inspect\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for Jupyter Notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/'\n",
    "rides = download_data_files(url, year=2023)\n",
    "rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/raw/2024/yellow_tripdata_2024-01.parquet'\n",
    "rides = validate_and_save_data(path, 2023, 1)\n",
    "rides.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the raw data files\n",
    "raw_data_dir = './data/raw/2023/'\n",
    "\n",
    "# Get a list of all .parquet files in the directory\n",
    "parquet_files = glob.glob(f\"{raw_data_dir}*.parquet\")\n",
    "\n",
    "# Regular expression to extract year and month from the filename\n",
    "pattern = re.compile(r'yellow_tripdata_(\\d{4})-(\\d{2})\\.parquet')\n",
    "\n",
    "# Process each file\n",
    "for path in parquet_files:\n",
    "    # Extract year and month from the file name using regex\n",
    "    filename = path.split('/')[-1]\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        year, month = map(int, match.groups())\n",
    "        \n",
    "        # Validate and save data\n",
    "        rides = validate_and_save_data(path, year, month)\n",
    "        \n",
    "        # Display the last few rows of the DataFrame\n",
    "        print(f\"File: {filename}\")\n",
    "        print(rides.tail())\n",
    "    else:\n",
    "        print(f\"Filename does not match expected pattern: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Path('./data/raw/2023')\n",
    "g = Path('./data/raw/2023')\n",
    "join_parquet_files(f,g, 'yellow_tripdata_2023.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = transform_data(rides) \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = add_missing_times(a, 'h')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_save_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the raw data files\n",
    "raw_data_dir = './data/bronze/2023/'\n",
    "\n",
    "# Get a list of all .parquet files in the directory\n",
    "parquet_files = glob.glob(f\"{raw_data_dir}*.parquet\")\n",
    "\n",
    "# Regular expression to extract year and month from the filename\n",
    "pattern = re.compile(r'validated_yellow_tripdata_(\\d{4})-(\\d{2})\\.parquet')\n",
    "\n",
    "# Process each file\n",
    "for path in parquet_files:\n",
    "    # Extract year and month from the file name using regex\n",
    "    filename = path.split('/')[-1]\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        year, month = map(int, match.groups())\n",
    "        \n",
    "        # Load the data into a DataFrame\n",
    "        rides = pd.read_parquet(path)\n",
    "        \n",
    "        # Transform and save data into time series data\n",
    "        ts_data = transform_save_data_into_ts_data(rides)\n",
    "        \n",
    "        # Display the last few rows of the transformed DataFrame\n",
    "        print(f\"File: {filename}\")\n",
    "        print(ts_data.tail())\n",
    "    else:\n",
    "        print(f\"Filename does not match expected pattern: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Path('./data/bronze/2023')\n",
    "g1 = Path('./data/bronze/2023')\n",
    "join_parquet_files(f1,g1, 'validated_yellow_tripdata_2023.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Path('./data/silver/2023')\n",
    "g = Path('./data/silver/2023')\n",
    "join_parquet_files(f,g, 'ts_data_2023.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import slice_and_slide\n",
    "j = transform_save_data_into_ts_data(rides)\n",
    "slice_and_slide(j, start_position = 0, n_features = 24*7, step_size = 1, target_col= 'ride_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = pd.read_parquet(\"./data/silver/2023/ts_data_2023-02.parquet\")\n",
    "f = generate_training_set(e, start_position = 0, n_features = 24*7*3*1, step_size = 24, pickup_location_id=43, target_col='ride_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet('./data/silver/2023/ts_data_2023-03.parquet').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the raw data files\n",
    "raw_data_dir = './data/silver/2023/'\n",
    "\n",
    "# Get a list of all .parquet files in the directory\n",
    "parquet_files = glob.glob(f\"{raw_data_dir}*.parquet\")\n",
    "\n",
    "# Regular expression to extract year and month from the filename\n",
    "pattern = re.compile(r'ts_data_(\\d{4})-(\\d{2})\\.parquet')\n",
    "\n",
    "# Process each file\n",
    "for path in parquet_files:\n",
    "    # Extract year and month from the file name using regex\n",
    "    filename = path.split('/')[-1]\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        year, month = map(int, match.groups())\n",
    "        \n",
    "        # Load the data into a DataFrame\n",
    "        rides = pd.read_parquet(path)\n",
    "        \n",
    "        # Generate the training set\n",
    "        training_set = generate_training_set(rides, start_position=0, n_features=24*7*4*1, step_size=24, target_col='ride_count')\n",
    "        \n",
    "        # Check if the training set was successfully generated\n",
    "        if training_set is not None:\n",
    "            # Continue processing the training_set\n",
    "            # (Add your processing code here)\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Skipping file {filename} due to insufficient data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Path('./data/gold/2023/')\n",
    "g = Path('./data/gold/2023/')\n",
    "join_parquet_files(f,g, 'model_data_2023.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signature = inspect.signature(validate_and_save_data)\n",
    "parameters = signature.parameters\n",
    "# Print the parameters using a list comprehension\n",
    "parameters_list = [f\"Parameter: {param_name}, Default: {param.default}\" for param_name, param in parameters.items()]\n",
    "print(parameters_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxi-demand-predictor-A_2bi8Y3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
